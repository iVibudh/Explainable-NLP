{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fa555b7",
   "metadata": {},
   "source": [
    "# Explainability of TFIDF based classification algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f6314c",
   "metadata": {},
   "source": [
    "## Motivation \n",
    "\n",
    "When you try to build Natural Language Processing (NLP) models it could be tedious to understand the model. At times, one might not be confident if the training data is large enough or if the quality of the samples are good enough. As a Data Scientist you do not want to train models on text which might be irrelevant to the NLP task. Hence, understanding your NLP model and the training data at an early stage of model development can go a long way. \n",
    "\n",
    "This notebook focuses on understanding the TFIDF based classification algorithm. I have chosen a simple model for explainability of your NLP model as most Machine Learning Engineers tend to start with a simple model before experimenting with more complex models. In this notebook we will try to understand the global explainability of the model and then further take some examples to understand the local explainability. \n",
    "\n",
    "## 1. Model description \n",
    "For this demonstration we will be using the [IMDB dataset](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews?resource=download) open scource dataset. This dataset has 25,000 highly polar movie reviews for training and 25,000 for testing. We will be using sklearn's TfidfVectorizer and then we will be using sklearn's SelectKBest to get the top keywords. Further, we will be using Random Forest alghorithm to classify the movie reviews into positive or negative reviews. \n",
    "\n",
    "## 2. Explainability \n",
    "**Global Explainability:** Once we have obtained satisfactory results with our random forerst classification model. We will further try to understand the top keywords and their contributions to the classification model. This global explainability helps in understanding the overall performance of the model. We should be getting relevant keywords as strong contributors to our model prediction. \n",
    "\n",
    "**Local Explainability:** Further we will be focusing on a few examples to undersating what keywords were the major contributors in making a prediction. I believe that Local Explainability can be very helpful for human in the loop use cases. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc7bf21",
   "metadata": {},
   "source": [
    "## 3. Model Building \n",
    "\n",
    "Let's dive in to build the model! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b449de",
   "metadata": {},
   "source": [
    "### 3.1 Data preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f778dba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, accuracy_score\n",
    "\n",
    "import matplotlip.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5e75394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Path: /home/vib/Desktop/Github/Explainable-NLP/TFIDF\n",
      "Root Path: /home/vib/Desktop/Github/Explainable-NLP\n"
     ]
    }
   ],
   "source": [
    "# Get path locations \n",
    "path_current = os.getcwd()\n",
    "print(\"Current Path:\", path_current)\n",
    "\n",
    "os.chdir('../')\n",
    "path_root = os.getcwd()\n",
    "print(\"Root Path:\", path_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69bfc82",
   "metadata": {},
   "source": [
    "Make sure that you have downloaded the IMDB Dataset and if is stored in the currect folder. Then let's load the data and review it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "588fb732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "5  Probably my all-time favorite movie, a story o...  positive\n",
       "6  I sure would like to see a resurrection of a u...  positive\n",
       "7  This show was an amazing, fresh & innovative i...  negative\n",
       "8  Encouraged by the positive comments about this...  negative\n",
       "9  If you like original gut wrenching laughter yo...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "df_data = pd.read_csv(path_root + '//data//IMDB Dataset.csv')\n",
    "df_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f1cf765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Loved today's show!!! It was a variety and not...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               50000     50000\n",
       "unique                                              49582         2\n",
       "top     Loved today's show!!! It was a variety and not...  positive\n",
       "freq                                                    5     25000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data exploration \n",
    "df_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "405dd061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    25000\n",
       "negative    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sentiment count\n",
    "df_data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7fae411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewer mentioned watching oz episode hoo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production br br filming tech...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically family little boy jake think zombie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei love time money visually stunnin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one reviewer mentioned watching oz episode hoo...         1\n",
       "1  wonderful little production br br filming tech...         1\n",
       "2  thought wonderful way spend time hot summer we...         1\n",
       "3  basically family little boy jake think zombie ...         0\n",
       "4  petter mattei love time money visually stunnin...         1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining functions to clean up the reviews dataframe\n",
    "def label_preprocess(row):\n",
    "    \"\"\"\n",
    "    Doed the following conversions:\n",
    "    positive: 1\n",
    "    negative: 0 \n",
    "    \"\"\"\n",
    "    if row.sentiment == 'positive':\n",
    "        row.sentiment = 1\n",
    "    else:\n",
    "        row.sentiment = 0\n",
    "    return row\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()   \n",
    "def text_preprocess(ds: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Remove digits, stopwords, lemmatize \n",
    "    \"\"\"\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    for index in range(len(ds)):\n",
    "        main_words = re.sub('[^a-zA-Z]', ' ', ds[index])                                  # Retain only alphabets\n",
    "        main_words = (main_words.lower()).split()                                         # Lower case and tokenize\n",
    "        main_words = [w for w in main_words if not w in set(stopwords.words('english'))]  # Remove stopwords\n",
    "                                                       \n",
    "        main_words = [lemmatizer.lemmatize(w) for w in main_words if len(w) > 1]          # lemmatization     \n",
    "        main_words = ' '.join(main_words)\n",
    "        ds[index] = main_words\n",
    "    return ds\n",
    "\n",
    "df_data['review'] = text_preprocess(df_data['review'])\n",
    "\n",
    "df_data.apply(label_preprocess, axis = 'columns')\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dcdb8a",
   "metadata": {},
   "source": [
    "### 3.2 Prepare Training and Test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25eafd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n",
      "10000\n",
      "40000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Split the data into test and train set\n",
    "X = df_data['review']\n",
    "y = df_data['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=19)\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667700b9",
   "metadata": {},
   "source": [
    "### 3.3 Create TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f62a57d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<40000x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3440577 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features = 5000, \n",
    "                                   sublinear_tf = True, \n",
    "                                   max_df = 0.7, \n",
    "                                   ngram_range = (1,3))\n",
    "\n",
    "X_train_vectors = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_train_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "916b881f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vib/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/vib/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 5000)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abc</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absence</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>absolutely nothing</th>\n",
       "      <th>absurd</th>\n",
       "      <th>abuse</th>\n",
       "      <th>...</th>\n",
       "      <th>young</th>\n",
       "      <th>young boy</th>\n",
       "      <th>young girl</th>\n",
       "      <th>young man</th>\n",
       "      <th>young woman</th>\n",
       "      <th>younger</th>\n",
       "      <th>youth</th>\n",
       "      <th>zero</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.167999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abandoned  abc  ability  able  absence  absolute  absolutely  \\\n",
       "0        0.0  0.0      0.0   0.0      0.0       0.0         0.0   \n",
       "1        0.0  0.0      0.0   0.0      0.0       0.0         0.0   \n",
       "2        0.0  0.0      0.0   0.0      0.0       0.0         0.0   \n",
       "3        0.0  0.0      0.0   0.0      0.0       0.0         0.0   \n",
       "4        0.0  0.0      0.0   0.0      0.0       0.0         0.0   \n",
       "\n",
       "   absolutely nothing  absurd  abuse  ...     young  young boy  young girl  \\\n",
       "0                 0.0     0.0    0.0  ...  0.097754        0.0         0.0   \n",
       "1                 0.0     0.0    0.0  ...  0.000000        0.0         0.0   \n",
       "2                 0.0     0.0    0.0  ...  0.000000        0.0         0.0   \n",
       "3                 0.0     0.0    0.0  ...  0.000000        0.0         0.0   \n",
       "4                 0.0     0.0    0.0  ...  0.000000        0.0         0.0   \n",
       "\n",
       "   young man  young woman  younger  youth  zero  zombie  zone  \n",
       "0        0.0     0.167999      0.0    0.0   0.0     0.0   0.0  \n",
       "1        0.0     0.000000      0.0    0.0   0.0     0.0   0.0  \n",
       "2        0.0     0.000000      0.0    0.0   0.0     0.0   0.0  \n",
       "3        0.0     0.000000      0.0    0.0   0.0     0.0   0.0  \n",
       "4        0.0     0.000000      0.0    0.0   0.0     0.0   0.0  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feature_names = pd.DataFrame(columns = tfidf_vectorizer.get_feature_names())\n",
    "X_train_vectors = pd.DataFrame(X_train_vectors.toarray(), \n",
    "                               columns = tfidf_vectorizer.get_feature_names())\n",
    "print(X_train_vectors.shape)\n",
    "X_train_vectors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8398b5b",
   "metadata": {},
   "source": [
    "### 3.4 Feature Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d85dde89",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_vectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m selector \u001b[38;5;241m=\u001b[39m SelectKBest(f_classif, \n\u001b[1;32m      2\u001b[0m                        k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m X_train_select_vectors \u001b[38;5;241m=\u001b[39m selector\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mX_train_vectors\u001b[49m, \n\u001b[1;32m      4\u001b[0m                                                 y_train)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_train_select_vectors\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      6\u001b[0m X_train_select_vectors\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_vectors' is not defined"
     ]
    }
   ],
   "source": [
    "selector = SelectKBest(f_classif, \n",
    "                       k = 200)\n",
    "X_train_select_vectors = selector.fit_transform(X_train_vectors, \n",
    "                                                y_train)\n",
    "print(X_train_select_vectors.shape)\n",
    "X_train_select_vectors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23e74b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get coloumns to keep and create new dataframe with selected features only \n",
    "cols = selector.get_support(indices = True)\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e1a2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_new = df_features_new.iloc[:, cols]\n",
    "print(\"Selected Vectors: \", len(df_features_new.columns))\n",
    "X_train_new_features = pd.DataFrame(X_train_select_vectors, \n",
    "                                    columns = df_feature_new.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ce50f1",
   "metadata": {},
   "source": [
    "### 3.5 Get selected vectors for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6341025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vectors = tfidf_vectorizer.transform(X_test)\n",
    "X_test_select_vectors = selector.transform(X_test_vectors)\n",
    "X_test_new_features = pd.DataFrame(X_test_select_vectors, \n",
    "                                   columns = df_feature_new.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1e9585",
   "metadata": {},
   "source": [
    "### 3.6 Implement Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcce4cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassification(n_estimators = 100, \n",
    "                                    random_state = 19)\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = forest.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print(\"F1 score: \", f1_score(y_test, y_test_pred))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca680c5",
   "metadata": {},
   "source": [
    "### 3.7 Global explainability: Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70098aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis = 0)\n",
    "df_feature_importance = pd.DataFrame({'feature': df_feature_importance.columns, \n",
    "                                      'importance': importances})\n",
    "df_feature_importance = df_feature_importance.sort_values(by = 'importance', \n",
    "                                                          ascending = False).reset_index(drop = True)\n",
    "df_top_feature_importance = df_feature_importance.head(25).copy() \n",
    "\n",
    "# plot the importance of 25 top features\n",
    "plt.barh(df_top_feature_importance.feature, df_top_feature_importance.importance)\n",
    "plt.show()\n",
    "\n",
    "df_feature_importance.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7104b0",
   "metadata": {},
   "source": [
    "### 3.8 Local explaiability using Shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6a5cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1758ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669c9017",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88d6db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Using SHAP Values to Explain How Your Machine Learning Model Works\n",
    "Ref -> https://towardsdatascience.com/using-shap-values-to-explain-how-your-machine-learning-model-works-732b3f40e137"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
